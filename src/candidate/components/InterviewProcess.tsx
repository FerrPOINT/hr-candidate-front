import { useState, useEffect, useRef, useCallback, useMemo } from 'react';
import { useLocation } from 'react-router-dom';
import { Button } from './';
import { HelpModal, HelpButton, WMTLogo } from './';
import { InstructionsModal } from './InstructionsModal';
import { AIAvatarWithWaves } from './AIAvatarWithWaves';
import { Loader2 } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';

// Import types and utilities
import { ProcessStage, AIMessage, QuestionCard } from './interview/types';
import { processQuestions, readingText } from './interview/constants';
import { apiClient } from '../../api/apiClient';
import { getFullAudioUrl, logAudioUrl } from '../../utils/audioUtils';
import { createQuestionCard, markQuestionAsCompleted, updateQuestionTime } from './interview/utils';
import { useAudioRecording } from '../hooks/useAudioRecording';

// Import components
import { MessageBubble } from './interview/MessageBubble';
import { QuestionProgressIndicator } from './interview/QuestionProgressIndicator';
import { QuestionCardComponent } from './interview/QuestionCardComponent';
import { MicrophoneTestCard } from './interview/MicrophoneTestCard';
import { ReadingTestCard } from './interview/ReadingTestCard';
import { CandidateQuestions } from './CandidateQuestions';

export function InterviewProcess() {
  const [stage, setStage] = useState<ProcessStage>('welcome');
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0);
  const [timeRemaining, setTimeRemaining] = useState(150);
  const [isRecording, setIsRecording] = useState(false);
  const [isHelpModalOpen, setIsHelpModalOpen] = useState(false);
  const [isInstructionsModalOpen, setIsInstructionsModalOpen] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isSavingAnswer, setIsSavingAnswer] = useState(false);
  const [showContinueButton, setShowContinueButton] = useState(false);
  const [messages, setMessages] = useState<(AIMessage | { id: string; content: string; isVisible: boolean; isNew: boolean; isUser: boolean })[]>([]);
  const [questionCards, setQuestionCards] = useState<QuestionCard[]>([]); // –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
  const [userResponse, setUserResponse] = useState(''); // –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
  const [currentMessageIndex, setCurrentMessageIndex] = useState(0);
  const [isAISpeaking, setIsAISpeaking] = useState(true);
  const [showMicrophoneCard, setShowMicrophoneCard] = useState(false);
  const [timerStarted, setTimerStarted] = useState(false);
  const [totalQuestions, setTotalQuestions] = useState<number | null>(null);
  const [currentQuestionNumber, setCurrentQuestionNumber] = useState<number | null>(null);
  const [currentQuestionId, setCurrentQuestionId] = useState<number | null>(null);
  const [initialData, setInitialData] = useState<any | null>(null);
  
  const timerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const messageTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const scrollContainerRef = useRef<HTMLDivElement>(null);
  const skipQuestionFnRef = useRef<(() => void) | null>(null);

  // –ê—É–¥–∏–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ welcome-—Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ API
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const welcomeQueueRef = useRef<{ id: string; text: string; audioUrl?: string }[]>([]);
  const completionQueueRef = useRef<{ id: string; text: string; audioUrl?: string }[]>([]);
  const testMessageRef = useRef<{ text?: string; audioUrl?: string } | null>(null);
  const positiveResponsesRef = useRef<{ text?: string; audioUrl?: string }[]>([]);
  const negativeResponsesRef = useRef<{ text?: string; audioUrl?: string }[]>([]);
  const additionalQuestionsRef = useRef<{ question?: string; answer?: string }[]>([]);

  // –ü–æ–ª—É—á–∞–µ–º interviewId –∏–∑ URL (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–æ—É—Ç–∏–Ω–≥–∞)
  const location = useLocation();
  const interviewId = useMemo(() => {
    const parts = location.pathname.split('/');
    const idx = parts.indexOf('interview');
    if (idx !== -1 && parts[idx + 1]) {
      const parsed = parseInt(parts[idx + 1], 10);
      return Number.isFinite(parsed) ? parsed : 1;
    }
    return 1;
  }, [location.pathname]);

  // –ù–ê–î–ï–ñ–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –∞–≤—Ç–æ—Å–∫—Ä–æ–ª–ª–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
  const scrollToBottom = useCallback(() => {
    const container = scrollContainerRef.current;
    if (!container) return;

    // –ù–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫ —Å–∫—Ä–æ–ª–ª–∞ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    const scroll = () => {
      container.scrollTop = container.scrollHeight;
    };

    // –ù–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞
    scroll();
    
    // –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ requestAnimationFrame
    requestAnimationFrame(scroll);
    
    // –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ setTimeout
    setTimeout(scroll, 50);
    
    // –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ –±–æ–ª—å—à–∏–π timeout
    setTimeout(scroll, 200);
  }, []);

  // Initialize welcome messages from API with audio sequencing
  useEffect(() => {
    let isCancelled = false;
    const loadAndPlayWelcome = async () => {
      try {
        setIsAISpeaking(true);
        setShowMicrophoneCard(false);
        setMessages([]);
        // –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        const resp = await apiClient.candidates.getInterviewData(interviewId);
        if (isCancelled) return;
        setInitialData(resp.data);
        const items = ((resp.data as any)?.welcome?.messages || []).map((m: any, idx: number) => ({ id: `welcome-${idx}`, text: m.text || '', audioUrl: m.audioUrl }));
        welcomeQueueRef.current = items;
        testMessageRef.current = (resp.data as any)?.test?.testMessage || null;
        positiveResponsesRef.current = (resp.data as any)?.test?.testPositiveResponses || [];
        negativeResponsesRef.current = (resp.data as any)?.test?.testNegativeResponses || [];
        completionQueueRef.current = (((resp.data as any)?.completion?.messages) || []).map((m: any, idx: number) => ({ id: `completion-${idx}`, text: m?.text || '', audioUrl: m?.audioUrl }));
        additionalQuestionsRef.current = ((resp.data as any)?.additionalQuestions || []) as any[];

        const playIndex = async (index: number) => {
          if (isCancelled) return;
          if (index >= welcomeQueueRef.current.length) {
            // After all messages, show microphone card
            const microphoneCard = { 
              id: 'microphone-card', 
              content: 'microphone-card', 
              isVisible: true, 
              isNew: true,
              type: 'microphone-card'
            } as any;
            setMessages(prev => [...prev, microphoneCard]);
            setShowMicrophoneCard(true);
            setIsAISpeaking(false);
            // –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å audioUrl
            const t = testMessageRef.current;
            if (t?.text) {
              const id = `test-msg`;
              setMessages(prev => [...prev, { id, content: t.text!, isVisible: true, isNew: true } as any]);
              setTimeout(() => setMessages(prev => prev.map(m => (m.id === id ? { ...m, isNew: false } : m))), 500);
              scrollToBottom();
            }
            if (t?.audioUrl) {
              try {
                const fullUrl = getFullAudioUrl(t.audioUrl);
                logAudioUrl(t.audioUrl, fullUrl, 'InterviewProcess:TestMessage');
                if (audioRef.current) audioRef.current.pause();
                const audio = new Audio(fullUrl);
                audioRef.current = audio;
                setIsAISpeaking(true);
                audio.onended = () => { setIsAISpeaking(false); };
                audio.onerror = () => { setIsAISpeaking(false); };
                await audio.play();
              } catch {
                setIsAISpeaking(false);
              }
            }
            // Scroll updates
            setTimeout(() => scrollToBottom(), 10);
            setTimeout(() => scrollToBottom(), 100);
            setTimeout(() => scrollToBottom(), 300);
            return;
          }

          const item = welcomeQueueRef.current[index];
          setCurrentMessageIndex(index);
          // Show message bubble
          setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
          setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
          scrollToBottom();

          // Play audio if available
          if (item.audioUrl) {
            const fullUrl = getFullAudioUrl(item.audioUrl);
            logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Welcome');
            try {
              if (audioRef.current) {
                audioRef.current.pause();
              }
              const audio = new Audio(fullUrl);
              audioRef.current = audio;
              setIsAISpeaking(true);
              audio.onended = () => {
                setIsAISpeaking(false);
                playIndex(index + 1);
              };
              audio.onerror = () => {
                setIsAISpeaking(false);
                playIndex(index + 1);
              };
              await audio.play();
            } catch (e) {
              setIsAISpeaking(false);
              playIndex(index + 1);
            }
          } else {
            // No audio ‚Äî proceed immediately
            setIsAISpeaking(false);
            playIndex(index + 1);
          }
        };

        playIndex(0);
      } catch (e) {
        // On failure, don't block UI: show microphone card
        const microphoneCard = { 
          id: 'microphone-card', 
          content: 'microphone-card', 
          isVisible: true, 
          isNew: true,
          type: 'microphone-card'
        } as any;
        setMessages(prev => [...prev, microphoneCard]);
        setShowMicrophoneCard(true);
        setIsAISpeaking(false);
      }
    };

    loadAndPlayWelcome();
    return () => {
      isCancelled = true;
      if (messageTimerRef.current) {
        clearTimeout(messageTimerRef.current);
      }
      if (audioRef.current) {
        audioRef.current.onended = null;
        audioRef.current.onerror = null;
        audioRef.current.pause();
      }
    };
  }, [scrollToBottom]);

  // –ü—Ä–æ—Å—Ç–æ–π –∞–≤—Ç–æ—Å–∫—Ä–æ–ª–ª –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
  useEffect(() => {
    scrollToBottom();
  }, [messages, scrollToBottom]);



  // Timer logic
  useEffect(() => {
    if ((stage === 'question' || stage === 'recording-answer') && timerStarted && timeRemaining > 0) {
      timerRef.current = setTimeout(() => {
        setTimeRemaining(prev => {
          const newTime = prev - 1;
          console.log(`‚è∞ Timer tick: ${newTime} seconds remaining`, { stage, timerStarted });
          setQuestionCards(prev => updateQuestionTime(prev, newTime));
          return newTime;
        });
      }, 1000);
    } else if (timeRemaining === 0 && (stage === 'question' || stage === 'recording-answer') && timerStarted) {
      // –í—Ä–µ–º—è –∏—Å—Ç–µ–∫–ª–æ ‚Äî –¥–µ–π—Å—Ç–≤—É–µ–º –∫–∞–∫ ¬´–ø—Ä–æ–ø—É—Å–∫ –≤–æ–ø—Ä–æ—Å–∞¬ª
      console.log('‚è∞ Time up for question', currentQuestionIndex + 1);
      if (skipQuestionFnRef.current) {
        skipQuestionFnRef.current();
      }
    }

    return () => {
      if (timerRef.current) {
        clearTimeout(timerRef.current);
      }
    };
  }, [timeRemaining, stage, timerStarted, currentQuestionIndex]);

  const addQuestionCard = useCallback((questionIndex: number, textOverride?: string) => {
    console.log(`‚ûï Adding question card ${questionIndex + 1}`);
    const base = createQuestionCard(questionIndex, processQuestions);
    const newQuestionCard = { ...base, text: textOverride ?? base.text } as QuestionCard;
    setQuestionCards(prev => [...prev, newQuestionCard]);
    
    // –î–æ–±–∞–≤–ª—è–µ–º question card –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
    const questionCardMsg = { 
      id: `question-card-${questionIndex}`, 
      content: `question-card-${questionIndex}`, 
      isVisible: true, 
      isNew: true,
      type: 'question-card',
      questionCard: newQuestionCard
    } as any;
    setMessages(prev => [...prev, questionCardMsg]);
    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
    
    setTimeout(() => {
      setQuestionCards(prev => prev.map(card =>
        card.id === newQuestionCard.id ? { ...card, isNew: false } : card
      ));
      setMessages(prev => prev.map(msg => 
        msg.id === `question-card-${questionIndex}` ? { ...msg, isNew: false } : msg
      ));
    }, 500);
  }, []);

  const completeQuestion = useCallback((questionIndex: number) => {
    console.log(`‚úÖ Completing question ${questionIndex + 1}`);
    setQuestionCards(prev => markQuestionAsCompleted(prev, questionIndex));
  }, []);

  // Event handlers
  const { isRecording: isRec, startRecording, stopRecording, audioBlob, clearAudio } = useAudioRecording();

  const handleMicrophoneTest = useCallback(() => {
    console.log('üé§ Starting microphone test');
    setStage('recording-test');
    setIsRecording(true);
    void startRecording();
    setIsAISpeaking(false);
    
    // –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–æ—Å—å–±–æ–π –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ (–ø–æ—è–≤–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏)
    const readingMessage = { 
      id: 'reading-message', 
      content: '–ü—Ä–æ—á–∏—Ç–∞–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ "–•–æ—Ç–∏—Ç–µ –ø–æ–Ω—è—Ç—å –¥—Ä—É–≥–∏—Ö ‚Äì –ø—Ä–∏—Å—Ç–∞–ª—å–Ω–µ–µ —Å–º–æ—Ç—Ä–∏—Ç–µ –≤ —Å–∞–º–æ–≥–æ —Å–µ–±—è."', 
      isVisible: true, 
      isNew: true
    } as any;
    setMessages(prev => [...prev, readingMessage]);
    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
  }, []);

  const handleContinueToInstructions = useCallback(() => {
    console.log('üìã Opening instructions modal');
    setShowContinueButton(false);
    setIsInstructionsModalOpen(true);
  }, []);

  const handleStopMicrophoneTest = useCallback(async () => {
    console.log('‚èπÔ∏è Stopping microphone test');
    setIsRecording(false);
    try {
      stopRecording();
    } catch {}
    setIsTranscribing(true);

    // –î–æ–∂–∏–¥–∞–µ–º—Å—è –ø–æ—è–≤–ª–µ–Ω–∏—è blob –∏–∑ —Ö—É–∫–∞
    const waitForBlob = async (retries = 20): Promise<Blob | null> => {
      for (let i = 0; i < retries; i++) {
        if (audioBlob) return audioBlob;
        await new Promise(r => setTimeout(r, 50));
      }
      return audioBlob || null;
    };
    const blob = await waitForBlob();
    try {
      let resp: any = { data: {} };
      if (blob) {
        const file = new File([blob], 'mic-test.wav', { type: 'audio/wav' });
        resp = await apiClient.candidates.testMicrophone(interviewId, file);
      }
      setIsTranscribing(false);

      // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (—ç–º—É–ª—è—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ –∞—É–¥–∏–æ)
      if (blob) {
        const userMsg = { 
          id: 'user-response', 
          content: '–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞', 
          isVisible: true, 
          isNew: true, 
          isUser: true 
        } as any;
        setMessages(prev => [...prev, userMsg]);
        setTimeout(() => scrollToBottom(), 10);
      }

      const isOk = (resp.data as any)?.isReadyForInterview === true;
      const responses = isOk ? positiveResponsesRef.current : negativeResponsesRef.current;

      // –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ (–ø–µ—Ä–≤—ã–π), –∑–∞—Ç–µ–º, –µ—Å–ª–∏ ok, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
      const item = responses[0];
      if (item?.text) {
        const id = `test-feedback-${Date.now()}`;
        setMessages(prev => [...prev, { id, content: item.text!, isVisible: true, isNew: true } as any]);
        setTimeout(() => setMessages(prev => prev.map(m => (m.id === id ? { ...m, isNew: false } : m))), 500);
        scrollToBottom();
      }
      if (item?.audioUrl) {
        try {
          const fullUrl = getFullAudioUrl(item.audioUrl);
          logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:TestFeedback');
          if (audioRef.current) audioRef.current.pause();
          const audio = new Audio(fullUrl);
          audioRef.current = audio;
          setIsAISpeaking(true);
          audio.onended = () => { setIsAISpeaking(false); };
          audio.onerror = () => { setIsAISpeaking(false); };
          await audio.play();
        } catch { setIsAISpeaking(false); }
      }

      if (isOk) {
        setShowContinueButton(true);
      } else {
        // –†–∞–∑—Ä–µ—à–∞–µ–º –ø–æ–≤—Ç–æ—Ä —Ç–µ—Å—Ç–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É ¬´–¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞¬ª –≤–∏–¥–∏–º–æ–π
        setShowMicrophoneCard(true);
      }
      clearAudio();
    } catch (e) {
      setIsTranscribing(false);
      setShowMicrophoneCard(true);
      clearAudio();
    }
  }, [audioBlob, clearAudio, interviewId, scrollToBottom, stopRecording]);

  const handleStartInterview = useCallback(async () => {
    console.log('üöÄ Starting interview');
    setIsInstructionsModalOpen(false);
    setStage('question');
    setTimeRemaining(150);
    setCurrentQuestionIndex(0);
    setIsAISpeaking(true);
    setTimerStarted(false); // –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –ø–æ—Å–ª–µ –æ–∑–≤—É—á–∫–∏ –≤–æ–ø—Ä–æ—Å–∞

    try {
      await apiClient.candidates.startInterview(interviewId);
    } catch (e: any) {
      // –ü–æ–∫–∞–∑–∞—Ç—å –æ—à–∏–±–∫—É –∏ –Ω–µ –Ω–∞—á–∏–Ω–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é (–±–µ–∑ —Å–º–µ–Ω—ã —ç–∫—Ä–∞–Ω–∞)
      setIsAISpeaking(false);
      const errText = e?.message || '–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é';
      setMessages(prev => [...prev, { id: `err-${Date.now()}`, content: errText, isVisible: true, isNew: true } as any]);
      setTimeout(() => setMessages(prev => prev.map(m => m.id.startsWith('err-') ? { ...m, isNew: false } : m)), 500);
      return;
    }

    const fetchAndPlay = async () => {
      try {
        const { data } = await apiClient.candidates.getCurrentQuestion(interviewId);
        if (!data || !data.questionId) {
          try { await apiClient.candidates.endInterview(interviewId); } catch {}
          const playCompletion = async (idx: number) => {
            if (idx >= completionQueueRef.current.length) {
              // –ü–æ—Å–ª–µ completion ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
              const list = additionalQuestionsRef.current || [];
              list.forEach((item, i) => {
                if (item?.question) {
                  const idQ = `add-q-${i}-${Date.now()}`;
                  setMessages(prev => [...prev, { id: idQ, content: item.question!, isVisible: true, isNew: true } as any]);
                  setTimeout(() => setMessages(prev => prev.map(m => (m.id === idQ ? { ...m, isNew: false } : m))), 500);
                }
                if (item?.answer) {
                  const idA = `add-a-${i}-${Date.now()}`;
                  setMessages(prev => [...prev, { id: idA, content: item.answer!, isVisible: true, isNew: true, isUser: true } as any]);
                  setTimeout(() => setMessages(prev => prev.map(m => (m.id === idA ? { ...m, isNew: false } : m))), 500);
                }
              });
              setTimeout(() => scrollToBottom(), 10);
              setTimeout(() => scrollToBottom(), 100);
              setTimeout(() => scrollToBottom(), 300);
              setStage('candidate-questions');
              return;
            }
            const item = completionQueueRef.current[idx];
            setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
            setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
            scrollToBottom();
            if (item.audioUrl) {
              try {
                const fullUrl = getFullAudioUrl(item.audioUrl);
                logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Completion');
                if (audioRef.current) audioRef.current.pause();
                const audio = new Audio(fullUrl);
                audioRef.current = audio;
                setIsAISpeaking(true);
                audio.onended = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
                audio.onerror = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
                await audio.play();
              } catch {
                setIsAISpeaking(false);
                playCompletion(idx + 1);
              }
            } else {
              setIsAISpeaking(false);
              playCompletion(idx + 1);
            }
          };
          playCompletion(0);
          return;
        }

        setCurrentQuestionId(data.questionId || null);
        const qNum = ((data as any).index ?? 1) - 1;
        setCurrentQuestionNumber((data as any).index || 1);
        setTotalQuestions((data as any).total || null);
        setCurrentQuestionIndex(Math.max(0, qNum));
        addQuestionCard(Math.max(0, qNum), data.text || '');
        const cardId = `question-card-${Math.max(0, qNum)}`;
        setTimeout(() => setQuestionCards(prev => prev.map(card => card.id === cardId ? { ...card, isNew: false } : card)), 500);
        scrollToBottom();

        if (data.audioUrl) {
          try {
            const fullUrl = getFullAudioUrl(data.audioUrl);
            logAudioUrl(data.audioUrl, fullUrl, 'InterviewProcess:Question');
            if (audioRef.current) audioRef.current.pause();
            const audio = new Audio(fullUrl);
            audioRef.current = audio;
            setIsAISpeaking(true);
            audio.onended = () => { setIsAISpeaking(false); setTimerStarted(true); };
            audio.onerror = () => { setIsAISpeaking(false); setTimerStarted(true); };
            await audio.play();
          } catch { setIsAISpeaking(false); setTimerStarted(true); }
        } else {
          setIsAISpeaking(false);
          setTimerStarted(true);
        }
      } catch {}
    };

    fetchAndPlay();
  }, [addQuestionCard, interviewId, scrollToBottom]);

  const handleRecordAnswer = useCallback(() => {
    console.log('üéôÔ∏è Starting to record answer for question', currentQuestionIndex + 1);
    setStage('recording-answer');
    setIsRecording(true);
    setIsAISpeaking(false);
    void startRecording();
    // –ù–ï —Ç—Ä–æ–≥–∞–µ–º —Ç–∞–π–º–µ—Ä - –æ–Ω –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –µ—Å—Ç—å
  }, [currentQuestionIndex, startRecording]);

  const handleSkipQuestion = useCallback(async () => {
    console.log(`‚è≠Ô∏è Skipping question ${currentQuestionIndex + 1}`);
    completeQuestion(currentQuestionIndex);
    setTimerStarted(false);
    setTimeRemaining(150);
    try {
      if (currentQuestionId != null) {
        // –ü—Ä–æ–ø—É—Å–∫: skip=true –±–µ–∑ –∞—É–¥–∏–æ
        await apiClient.candidates.submitAnswer(interviewId, currentQuestionId, true);
      }
    } catch {}

    try {
      const { data } = await apiClient.candidates.getCurrentQuestion(interviewId);
      if (!data || !data.questionId) {
        try { await apiClient.candidates.endInterview(interviewId); } catch {}
        const playCompletion = async (idx: number) => {
          if (idx >= completionQueueRef.current.length) {
            const list = additionalQuestionsRef.current || [];
            list.forEach((item, i) => {
              if (item?.question) {
                const idQ = `add-q-${i}-${Date.now()}`;
                setMessages(prev => [...prev, { id: idQ, content: item.question!, isVisible: true, isNew: true } as any]);
                setTimeout(() => setMessages(prev => prev.map(m => (m.id === idQ ? { ...m, isNew: false } : m))), 500);
              }
              if (item?.answer) {
                const idA = `add-a-${i}-${Date.now()}`;
                setMessages(prev => [...prev, { id: idA, content: item.answer!, isVisible: true, isNew: true, isUser: true } as any]);
                setTimeout(() => setMessages(prev => prev.map(m => (m.id === idA ? { ...m, isNew: false } : m))), 500);
              }
            });
            setTimeout(() => scrollToBottom(), 10);
            setTimeout(() => scrollToBottom(), 100);
            setTimeout(() => scrollToBottom(), 300);
            setStage('candidate-questions');
            return;
          }
          const item = completionQueueRef.current[idx];
          setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
          setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
          scrollToBottom();
          if (item.audioUrl) {
            try {
              const fullUrl = getFullAudioUrl(item.audioUrl);
              logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Completion');
              if (audioRef.current) audioRef.current.pause();
              const audio = new Audio(fullUrl);
              audioRef.current = audio;
              setIsAISpeaking(true);
              audio.onended = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
              audio.onerror = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
              await audio.play();
            } catch {
              setIsAISpeaking(false);
              playCompletion(idx + 1);
            }
          } else {
            setIsAISpeaking(false);
            playCompletion(idx + 1);
          }
        };
        playCompletion(0);
        return;
      }

      setCurrentQuestionId(data.questionId || null);
      const qNumber = (((data as any).index ?? (currentQuestionIndex + 2)) as number) - 1;
      setCurrentQuestionNumber((data as any).index || (qNumber + 1));
      setTotalQuestions((data as any).total || totalQuestions);
      setCurrentQuestionIndex(Math.max(0, qNumber));
      addQuestionCard(Math.max(0, qNumber), data.text || '');
      const cardId = `question-card-${Math.max(0, qNumber)}`;
      setTimeout(() => setQuestionCards(prev => prev.map(card => card.id === cardId ? { ...card, isNew: false } : card)), 500);
      scrollToBottom();

      setIsAISpeaking(false);
      setTimerStarted(false);
      setTimeRemaining(150);
      if (data.audioUrl) {
        try {
          const fullUrl = getFullAudioUrl(data.audioUrl);
          logAudioUrl(data.audioUrl, fullUrl, 'InterviewProcess:Question');
          if (audioRef.current) audioRef.current.pause();
          const audio = new Audio(fullUrl);
          audioRef.current = audio;
          setIsAISpeaking(true);
          audio.onended = () => { setIsAISpeaking(false); setTimerStarted(true); };
          audio.onerror = () => { setIsAISpeaking(false); setTimerStarted(true); };
          await audio.play();
        } catch {
          setIsAISpeaking(false);
          setTimerStarted(true);
        }
      } else {
        setTimerStarted(true);
      }
    } catch {}
  }, [currentQuestionIndex, completeQuestion, addQuestionCard, currentQuestionId, interviewId, totalQuestions, scrollToBottom]);

  // –î–∞–µ–º —Ç–∞–π–º–µ—Ä—É –¥–æ—Å—Ç—É–ø –∫ –ª–æ–≥–∏–∫–µ –ø—Ä–æ–ø—É—Å–∫–∞
  useEffect(() => {
    skipQuestionFnRef.current = () => { void handleSkipQuestion(); };
  }, [handleSkipQuestion]);

  const handleStopRecording = useCallback(async () => {
    console.log('‚èπÔ∏è Stopping recording for question', currentQuestionIndex + 1);
    setIsRecording(false);
    try { stopRecording(); } catch {}
    setIsTranscribing(true);

    // –î–æ–∂–¥–∞—Ç—å—Å—è blob
    const waitForBlob = async (retries = 20): Promise<Blob | null> => {
      for (let i = 0; i < retries; i++) {
        if (audioBlob) return audioBlob;
        await new Promise(r => setTimeout(r, 50));
      }
      return audioBlob || null;
    };
    const blob = await waitForBlob();

    try {
      setIsSavingAnswer(true);
      if (currentQuestionId != null && blob) {
        const file = new File([blob], 'answer.wav', { type: 'audio/wav' });
        await apiClient.candidates.submitAnswer(interviewId, currentQuestionId, false, file);
      }
      setIsSavingAnswer(false);
      setIsTranscribing(false);
      completeQuestion(currentQuestionIndex);

      // –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
      const { data } = await apiClient.candidates.getCurrentQuestion(interviewId);
      if (!data || !data.questionId) {
        try { await apiClient.candidates.endInterview(interviewId); } catch {}
        const playCompletion = async (idx: number) => {
          if (idx >= completionQueueRef.current.length) {
            const list = additionalQuestionsRef.current || [];
            list.forEach((item, i) => {
              if (item?.question) {
                const idQ = `add-q-${i}-${Date.now()}`;
                setMessages(prev => [...prev, { id: idQ, content: item.question!, isVisible: true, isNew: true } as any]);
                setTimeout(() => setMessages(prev => prev.map(m => (m.id === idQ ? { ...m, isNew: false } : m))), 500);
              }
              if (item?.answer) {
                const idA = `add-a-${i}-${Date.now()}`;
                setMessages(prev => [...prev, { id: idA, content: item.answer!, isVisible: true, isNew: true, isUser: true } as any]);
                setTimeout(() => setMessages(prev => prev.map(m => (m.id === idA ? { ...m, isNew: false } : m))), 500);
              }
            });
            setTimeout(() => scrollToBottom(), 10);
            setTimeout(() => scrollToBottom(), 100);
            setTimeout(() => scrollToBottom(), 300);
            setStage('candidate-questions');
            return;
          }
          const item = completionQueueRef.current[idx];
          setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
          setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
          scrollToBottom();
          if (item.audioUrl) {
            try {
              const fullUrl = getFullAudioUrl(item.audioUrl);
              logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Completion');
              if (audioRef.current) audioRef.current.pause();
              const audio = new Audio(fullUrl);
              audioRef.current = audio;
              setIsAISpeaking(true);
              audio.onended = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
              audio.onerror = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
              await audio.play();
            } catch { setIsAISpeaking(false); playCompletion(idx + 1); }
          } else { setIsAISpeaking(false); playCompletion(idx + 1); }
        };
        playCompletion(0);
        return;
      }

      setCurrentQuestionId(data.questionId || null);
      const qNumber = (((data as any).index ?? (currentQuestionIndex + 2)) as number) - 1;
      setCurrentQuestionNumber((data as any).index || (qNumber + 1));
      setTotalQuestions((data as any).total || totalQuestions);
      setCurrentQuestionIndex(Math.max(0, qNumber));
      addQuestionCard(Math.max(0, qNumber), data.text || '');
      const cardId = `question-card-${Math.max(0, qNumber)}`;
      setTimeout(() => setQuestionCards(prev => prev.map(card => card.id === cardId ? { ...card, isNew: false } : card)), 500);
      scrollToBottom();

      setIsAISpeaking(false);
      setTimerStarted(false);
      setTimeRemaining(150);
      if (data.audioUrl) {
        try {
          const fullUrl = getFullAudioUrl(data.audioUrl);
          logAudioUrl(data.audioUrl, fullUrl, 'InterviewProcess:Question');
          if (audioRef.current) audioRef.current.pause();
          const audio = new Audio(fullUrl);
          audioRef.current = audio;
          setIsAISpeaking(true);
          audio.onended = () => { setIsAISpeaking(false); setTimerStarted(true); };
          audio.onerror = () => { setIsAISpeaking(false); setTimerStarted(true); };
          await audio.play();
        } catch { setIsAISpeaking(false); setTimerStarted(true); }
      } else {
        setTimerStarted(true);
      }
    } catch {
      setIsTranscribing(false);
      setIsSavingAnswer(false);
    }
  }, [addQuestionCard, audioBlob, completeQuestion, currentQuestionId, currentQuestionIndex, interviewId, scrollToBottom, stopRecording, totalQuestions]);

  const handleCandidateQuestionsComplete = useCallback(() => {
    console.log('üéâ Interview completed');
    setIsAISpeaking(false);
  }, []);

  // –î–æ–±–∞–≤–ª—è–µ–º AI —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç
  const handleAddAiMessage = useCallback((content: string) => {
    const msg = { 
      id: `ai-${Date.now()}`, 
      content, 
      isVisible: true, 
      isNew: true 
    } as AIMessage;
    setMessages(prev => [...prev, msg]);
    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
    
    setTimeout(() => {
      setMessages(prev => prev.map(m => (m.id === msg.id ? { ...m, isNew: false } : m)));
    }, 500);
  }, [scrollToBottom]);

  // –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç
  const handleAddUserMessage = useCallback((content: string) => {
    const msg = { 
      id: `user-${Date.now()}`, 
      content, 
      isVisible: true, 
      isNew: true, 
      isUser: true 
    } as any;
    setMessages(prev => [...prev, msg]);
    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
    
    setTimeout(() => {
      setMessages(prev => prev.map(m => (m.id === msg.id ? { ...m, isNew: false } : m)));
    }, 500);
  }, [scrollToBottom]);

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ AI —Ä–µ—á–∏ –¥–ª—è candidate-questions —ç—Ç–∞–ø–∞
  useEffect(() => {
    if (stage === 'candidate-questions') {
      console.log('üí¨ Starting candidate questions phase');
      setIsAISpeaking(true);
      
      const speakingTimer = setTimeout(() => {
        setIsAISpeaking(false);
      }, 8000);
      
      return () => clearTimeout(speakingTimer);
    }
  }, [stage]);

  const handleAISpeakingChange = useCallback((isSpeaking: boolean) => {
    setIsAISpeaking(isSpeaking);
  }, []);

  const handleNewMessage = useCallback(() => {
    scrollToBottom();
  }, [scrollToBottom]);

  // Debug info for current state
  console.log('üéØ Current state:', {
    stage,
    currentQuestionIndex,
    isRecording,
    isTranscribing,
    isSavingAnswer,
    isAISpeaking,
    timerStarted,
    timeRemaining
  });

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∞–≤–∞—Ç–∞—Ä
  const shouldShowAvatar = () => {
    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–≤–∞—Ç–∞—Ä –∫–æ–≥–¥–∞ AI –≥–æ–≤–æ—Ä–∏—Ç
    if (isAISpeaking && !isTranscribing && !isSavingAnswer) {
      return true;
    }
    
    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–≤–∞—Ç–∞—Ä –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –º–æ–ª—á–∞–Ω–∏—è –Ω–∞ —ç—Ç–∞–ø–µ candidate-questions
    if (stage === 'candidate-questions' && !isTranscribing && !isSavingAnswer) {
      return true;
    }
    
    return false;
  };

  // –ï–¥–∏–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
  const renderMessages = () => {
    return (
      <div className="flex flex-col space-y-4">
        {messages.map((message) => (
          message.isVisible && (
            <div key={message.id}>
              {('type' in message && message.type === 'microphone-card') ? (
                <div className="flex justify-start">
                  <MicrophoneTestCard />
                </div>
              ) : ('type' in message && message.type === 'reading-card') ? (
                <div className="flex justify-start">
                  <ReadingTestCard />
                </div>
              ) : ('type' in message && message.type === 'question-card' && 'questionCard' in message) ? (
                <div key={(message.questionCard as any).id}>
                  <QuestionProgressIndicator questionIndex={(message.questionCard as any).questionIndex} />
                                     <QuestionCardComponent 
                     questionCard={{
                       ...(message.questionCard as any),
                       timeRemaining: (message.questionCard as any).questionIndex === currentQuestionIndex && (stage === 'question' || stage === 'recording-answer') ? timeRemaining : null,
                       status: (message.questionCard as any).questionIndex === currentQuestionIndex && (stage === 'question' || stage === 'recording-answer') ? 'active' : 'completed'
                     }} 
                   />
                </div>
              ) : (
                <div className={`flex ${('isUser' in message && message.isUser) ? 'justify-end' : 'justify-start'}`}>
                  {message.id === 'reading-message' ? (
                    <div className="bg-white rounded-br-[24px] rounded-tl-[24px] rounded-tr-[24px] border border-[#e2e4e9] px-8 py-6 max-w-[421px]">
                      <h3 className="text-[#e16349] text-[16px] leading-[24px] tracking-[0.96px] uppercase font-medium font-Inter mb-3">
                        –ü—Ä–æ—á–∏—Ç–∞–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                      </h3>
                      <p className="text-[#0a0d14] text-[16px] leading-[24px] tracking-[-0.176px] font-medium font-Inter">
                        {message.content}
                      </p>
                    </div>
                  ) : (
                    <MessageBubble 
                      content={message.content} 
                      isNew={message.isNew} 
                      isUser={'isUser' in message ? message.isUser : false}
                    />
                  )}
                </div>
              )}
            </div>
          )
        ))}
        
        {/* –ü–æ–∫–∞–∑—ã–≤–∞–µ–º CandidateQuestions —Ç–æ–ª—å–∫–æ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º —ç—Ç–∞–ø–µ */}
        {stage === 'candidate-questions' && (
          <CandidateQuestions 
            onComplete={handleCandidateQuestionsComplete}
            onAISpeakingChange={handleAISpeakingChange}
            onNewMessage={handleNewMessage}
            onAddAiMessage={handleAddAiMessage}
            onAddUserMessage={handleAddUserMessage}
          />
        )}
      </div>
    );
  };

  // Render stage content
  const renderStageContent = () => {
    console.log(`üé¨ Rendering stage: ${stage}`);
    
    switch (stage) {
      case 'welcome':
      case 'recording-test':
      case 'question':
      case 'recording-answer':
      case 'question-completed':
      case 'candidate-questions':
        return renderMessages();

      default:
        return null;
    }
  };

  // –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–Ω–æ–ø–∫–∞ "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å" –ø–æ –æ–±—Ä–∞–∑—Ü—É –∏–∑ Figma
  const RecordingButton = () => (
    <button
      onClick={stage === 'recording-test' ? handleStopMicrophoneTest : handleStopRecording}
      className="bg-[#df1c41] relative rounded-[60px] h-16 w-auto hover:bg-[#c7193a] transition-colors duration-200 pulse-recording"
    >
      <div className="flex flex-row items-center relative size-full">
        <div className="box-border content-stretch flex flex-row gap-3 items-center justify-start pl-2 pr-8 py-2 relative size-full">
          {/* –ë–µ–ª—ã–π –∫—Ä—É–≥ —Å –∫—Ä–∞—Å–Ω—ã–º –∫–≤–∞–¥—Ä–∞—Ç–æ–º */}
          <div className="bg-[#ffffff] box-border content-stretch flex flex-row gap-2.5 items-center justify-center overflow-clip p-[8px] relative rounded-[100px] shrink-0 size-12">
            <div className="bg-[#df1c41] rounded shrink-0 size-5" />
          </div>
          {/* –¢–µ–∫—Å—Ç */}
          <div className="flex flex-col font-medium justify-center leading-[0] not-italic relative shrink-0 text-[#ffffff] text-[18px] text-center text-nowrap tracking-[-0.27px]">
            <p className="block leading-[24px] whitespace-pre font-Inter">–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å</p>
          </div>
        </div>
      </div>
    </button>
  );

  return (
    <div className="min-h-screen w-full" style={{ backgroundColor: 'var(--interview-bg)' }}>
      <div className="w-full h-full flex flex-col">
        <div className="flex flex-col gap-4 p-6 w-full h-full">
          
          {/* Header */}
          <div className="flex items-center justify-between w-full h-16">
            <WMTLogo size="medium" />
            <HelpButton onClick={() => setIsHelpModalOpen(true)} />
          </div>

          {/* Main Content Area - —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≤—ã—Å–æ—Ç–æ–π –∏ z-index */}
          <div 
            className="overflow-hidden relative z-40"
            style={{ 
              height: 'calc(100vh - 64px - 96px - 128px - 48px)', // 100vh - header(64px) - downbar(96px) - footer(128px) - padding(48px)
              maxHeight: 'calc(100vh - 64px - 96px - 128px - 48px)'
            }}
          >
            <div 
              ref={scrollContainerRef}
              className="h-full overflow-y-auto px-6 pb-4 custom-scroll-container"
            >
              <div className="max-w-4xl mx-auto">
                {renderStageContent()}
                <div ref={messagesEndRef} />
              </div>
            </div>
          </div>

          {/* Fixed Downbar - —Å –∞–Ω–∏–º–∞—Ü–∏–µ–π */}
          <div className="fixed bottom-32 left-0 right-0 pointer-events-none z-50">
            <div className="w-full max-w-2xl mx-auto px-6 pointer-events-auto">
              <AnimatePresence mode="wait">
                {/* AI Avatar */}
                {shouldShowAvatar() && (
                  <motion.div 
                    initial={{ opacity: 0, y: 20 }}
                    animate={{ opacity: 1, y: 0 }}
                    exit={{ opacity: 0, y: 20 }}
                    transition={{ duration: 0.4 }}
                    className="flex justify-center"
                    key="avatar"
                  >
                    <AIAvatarWithWaves 
                      size={stage === 'question-completed' ? 'small' : 'large'} 
                      isSpeaking={isAISpeaking}
                    />
                  </motion.div>
                )}
                
                {/* Loader */}
                {(isTranscribing || isSavingAnswer) && (
                  <motion.div 
                    initial={{ opacity: 0, y: 20 }}
                    animate={{ opacity: 1, y: 0 }}
                    exit={{ opacity: 0, y: 20 }}
                    transition={{ duration: 0.4 }}
                    className="flex justify-center"
                    key="loader"
                  >
                    <div className="text-white rounded-full h-16 w-16 flex items-center justify-center shadow-lg" style={{ backgroundColor: 'var(--interview-accent)' }}>
                      <Loader2 className="w-12 h-12 animate-spin" strokeWidth={2} />
                    </div>
                  </motion.div>
                )}
              </AnimatePresence>
            </div>
          </div>

          {/* Fixed Footer - —Å –∫–Ω–æ–ø–∫–∞–º–∏ */}
          <div className="fixed bottom-0 left-0 right-0 pointer-events-none z-50">
            {/* Gradient Background */}
            <div className="bottom-controls-gradient h-32" />
            
            {/* Controls Container */}
            <div className="absolute inset-0 flex items-end justify-center pointer-events-none">
              <div className="w-full max-w-2xl mx-auto px-6 pb-8 pointer-events-auto">
                {/* Action Buttons */}
                <div className="flex justify-center">
                  {/* Welcome Stage */}
                  {stage === 'welcome' && showMicrophoneCard && !isAISpeaking && !isTranscribing && !isSavingAnswer && (
                    <Button
                      onClick={handleMicrophoneTest}
                      className="bg-[var(--interview-accent)] hover:bg-[var(--interview-accent-hover)] text-white px-8 py-4 font-medium shadow-md transition-all duration-200 hover:shadow-lg text-lg"
                      style={{ borderRadius: '30px', height: '56px' }}
                    >
                      –¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                    </Button>
                  )}

                  {/* Recording Test Stage */}
                  {stage === 'recording-test' && showContinueButton && !isAISpeaking && !isTranscribing && !isSavingAnswer && (
                    <Button
                      onClick={handleContinueToInstructions}
                      className="bg-[var(--interview-accent)] hover:bg-[var(--interview-accent-hover)] text-white px-8 py-4 font-medium shadow-md transition-all duration-200 hover:shadow-lg text-lg"
                      style={{ borderRadius: '30px', height: '56px' }}
                    >
                      –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å
                    </Button>
                  )}

                  {/* Question Stage */}
                  {stage === 'question' && !isAISpeaking && !isRecording && !isTranscribing && !isSavingAnswer && (
                    <div className="flex flex-col sm:flex-row gap-4">
                      <Button
                        onClick={handleRecordAnswer}
                        className="bg-[var(--interview-accent)] hover:bg-[var(--interview-accent-hover)] text-white px-8 py-4 font-medium shadow-md transition-all duration-200 hover:shadow-lg text-lg"
                        style={{ borderRadius: '30px', height: '56px' }}
                      >
                        –ó–∞–ø–∏—Å–∞—Ç—å –æ—Ç–≤–µ—Ç
                      </Button>
                      <Button
                        onClick={handleSkipQuestion}
                        className="border-2 border-gray-300 text-gray-700 hover:border-gray-400 hover:bg-gray-50 px-8 py-4 font-medium shadow-md transition-all duration-200 bg-white text-lg"
                        style={{ borderRadius: '30px', height: '56px' }}
                      >
                        –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                      </Button>
                    </div>
                  )}

                  {/* Recording Buttons */}
                  {((stage === 'recording-answer' && isRecording) || (stage === 'recording-test' && isRecording)) && (
                    <RecordingButton />
                  )}
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <HelpModal 
        isOpen={isHelpModalOpen} 
        onClose={() => setIsHelpModalOpen(false)} 
      />

      <InstructionsModal
        isOpen={isInstructionsModalOpen}
        onClose={() => setIsInstructionsModalOpen(false)}
        onStartInterview={handleStartInterview}
      />
    </div>
  );
}
