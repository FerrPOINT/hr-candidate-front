import { useState, useEffect, useRef, useCallback } from 'react';
import { Button } from './';
import { HelpModal, HelpButton, Logo } from './';
import { InstructionsModal } from './InstructionsModal';
import { AIAvatarWithWaves } from './AIAvatarWithWaves';
import { Loader2, AlertCircle } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';

// Import types and utilities
import { ProcessStage, AIMessage, QuestionCard } from './interview/types';

import { apiClient } from '../../api/apiClient';
import { getFullAudioUrl, logAudioUrl } from '../../utils/audioUtils';
import { createQuestionCard, markQuestionAsCompleted, updateQuestionTime } from './interview/utils';
import { useAudioRecording } from '../hooks/useAudioRecording';

// Import components
import { MessageBubble } from './interview/MessageBubble';
import { QuestionProgressIndicator } from './interview/QuestionProgressIndicator';
import { QuestionCardComponent } from './interview/QuestionCardComponent';
import { MicrophoneTestCard } from './interview/MicrophoneTestCard';
import { ReadingTestCard } from './interview/ReadingTestCard';
import { CandidateQuestions } from './CandidateQuestions';

interface InterviewProcessProps {
  interviewId: number;
  token?: string;
  jobPosition?: {
    title: string;
    department: string;
    company: string;
    type: string;
    questionsCount: number;
  };
  candidateId?: string;
}

export function InterviewProcess({ interviewId, jobPosition }: InterviewProcessProps) {
  const [stage, setStage] = useState<ProcessStage>('welcome');
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0);
  const [timeRemaining, setTimeRemaining] = useState(150);
  const [isRecording, setIsRecording] = useState(false);
  const [isHelpModalOpen, setIsHelpModalOpen] = useState(false);
  const [isInstructionsModalOpen, setIsInstructionsModalOpen] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isSavingAnswer, setIsSavingAnswer] = useState(false);
  const [showContinueButton, setShowContinueButton] = useState(false);
  const [messages, setMessages] = useState<(AIMessage | { id: string; content: string; isVisible: boolean; isNew: boolean; isUser: boolean })[]>([]);
  const [questionCards, setQuestionCards] = useState<QuestionCard[]>([]); // –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
  const [userResponse, setUserResponse] = useState(''); // –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
  const [currentMessageIndex, setCurrentMessageIndex] = useState(0);
  const [isAISpeaking, setIsAISpeaking] = useState(true);
  const [showMicrophoneCard, setShowMicrophoneCard] = useState(false);
  const [timerStarted, setTimerStarted] = useState(false);
  const [totalQuestions, setTotalQuestions] = useState<number | null>(jobPosition?.questionsCount || null);
  const [currentQuestionNumber, setCurrentQuestionNumber] = useState<number | null>(null);
  const [currentQuestionId, setCurrentQuestionId] = useState<number | null>(null);
  const [initialData, setInitialData] = useState<any | null>(null);
  const [answerTimeSec, setAnswerTimeSec] = useState<number>(150);
  
  // –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –æ—à–∏–±–æ–∫
  const [error, setError] = useState<string | null>(null);
  const [isErrorModalOpen, setIsErrorModalOpen] = useState(false);
  
  const timerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const messageTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const scrollContainerRef = useRef<HTMLDivElement>(null);
  const skipQuestionFnRef = useRef<(() => void) | null>(null);
  const isStopInProgressRef = useRef<boolean>(false);

  // –ê—É–¥–∏–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ welcome-—Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ API
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const welcomeQueueRef = useRef<{ id: string; text: string; audioUrl?: string }[]>([]);
  const completionQueueRef = useRef<{ id: string; text: string; audioUrl?: string }[]>([]);
  const testMessageRef = useRef<{ text?: string; audioUrl?: string } | null>(null);
  const positiveResponsesRef = useRef<{ text?: string; audioUrl?: string }[]>([]);
  const negativeResponsesRef = useRef<{ text?: string; audioUrl?: string }[]>([]);
  const additionalQuestionsRef = useRef<{ question?: string; answer?: string }[]>([]);
  const currentQuestionIdRef = useRef<number | null>(null);

  // interviewId —Ç–µ–ø–µ—Ä—å –ø—Ä–∏—Ö–æ–¥–∏—Ç –∏–∑ –ø—Ä–æ–ø—Å–æ–≤ (Single Page)

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∫–∞–∑–∞ –æ—à–∏–±–∫–∏ –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –∏–Ω—Ç–µ—Ä–≤—å—é
  const showError = useCallback((errorMessage: string) => {
    console.error('‚ùå API Error:', errorMessage);
    setError(errorMessage);
    setIsErrorModalOpen(true);
    setIsAISpeaking(false);
    setIsTranscribing(false);
    setIsSavingAnswer(false);
    setIsRecording(false);
  }, []);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è –æ—à–∏–±–∫–∏
  const hideError = useCallback(() => {
    setError(null);
    setIsErrorModalOpen(false);
  }, []);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
  const retryLoading = useCallback(() => {
    hideError();
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π –ø—É—Ç—å –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
    const currentPath = window.location.pathname;
    window.location.href = currentPath;
  }, [hideError]);

  // –ù–ê–î–ï–ñ–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –∞–≤—Ç–æ—Å–∫—Ä–æ–ª–ª–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
  const scrollToBottom = useCallback(() => {
    const container = scrollContainerRef.current;
    if (!container) return;

    const scroll = () => { container.scrollTop = container.scrollHeight; };
    scroll();
    requestAnimationFrame(scroll);
    setTimeout(scroll, 50);
    setTimeout(scroll, 200);
  }, []);

  // Initialize welcome messages from API with audio sequencing
  useEffect(() => {
    let isCancelled = false;
    const loadAndPlayWelcome = async () => {
      try {
        setIsAISpeaking(true);
        setShowMicrophoneCard(false);
        setMessages([]);
        
        // –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤—å—é –Ω–∞–ø—Ä—è–º—É—é –∏–∑ API (Single Page, –±–µ–∑ localStorage)
        const resp = await apiClient.candidates.getInterviewData(interviewId);
        
        if (isCancelled) return;
        setInitialData(resp.data);
        const items = ((resp.data as any)?.welcome?.messages || []).map((m: any, idx: number) => ({ id: `welcome-${idx}`, text: m.text || '', audioUrl: m.audioUrl }));
        welcomeQueueRef.current = items;
        testMessageRef.current = (resp.data as any)?.test?.testMessage || null;
        positiveResponsesRef.current = (resp.data as any)?.test?.testPositiveResponses || [];
        negativeResponsesRef.current = (resp.data as any)?.test?.testNegativeResponses || [];
        completionQueueRef.current = (((resp.data as any)?.completion?.messages) || []).map((m: any, idx: number) => ({ id: `completion-${idx}`, text: m?.text || '', audioUrl: m?.audioUrl }));
        additionalQuestionsRef.current = ((resp.data as any)?.additionalQuestions || []) as any[];
        
        // answerTime –∏–∑ interview —Å–µ–∫—Ü–∏–∏ (—Å–µ–∫—É–Ω–¥—ã) —Å —Ñ–æ–ª–±—ç–∫–æ–º 150
        const answerTime = Number(((resp.data as any)?.interview?.answerTime)) || 150;
        setAnswerTimeSec(answerTime);
        setTimeRemaining(answerTime);

        const playIndex = async (index: number) => {
          if (isCancelled) return;
          if (index >= welcomeQueueRef.current.length) {
            const microphoneCard = { 
              id: 'microphone-card', 
              content: 'microphone-card', 
              isVisible: true, 
              isNew: true,
              type: 'microphone-card'
            } as any;
            setMessages(prev => [...prev, microphoneCard]);
            setShowMicrophoneCard(true);
            setIsAISpeaking(false);
            const t = testMessageRef.current;
            if (t?.text || t?.audioUrl) {
              setTimeout(async () => {
                if (t?.text) {
                  const id = `test-msg`;
                  setMessages(prev => [...prev, { id, content: t.text!, isVisible: true, isNew: true } as any]);
                  setTimeout(() => setMessages(prev => prev.map(m => (m.id === id ? { ...m, isNew: false } : m))), 500);
                  scrollToBottom();
                }
                if (t?.audioUrl) {
                  try {
                    const fullUrl = getFullAudioUrl(t.audioUrl);
                    logAudioUrl(t.audioUrl, fullUrl, 'InterviewProcess:TestMessage');
                    if (audioRef.current) audioRef.current.pause();
                    const audio = new Audio(fullUrl);
                    audioRef.current = audio;
                    setIsAISpeaking(true);
                    audio.onended = () => { setIsAISpeaking(false); };
                    audio.onerror = () => { setIsAISpeaking(false); };
                    await audio.play();
                  } catch {
                    setIsAISpeaking(false);
                  }
                }
              }, 1000);
            }
            setTimeout(() => scrollToBottom(), 10);
            setTimeout(() => scrollToBottom(), 100);
            setTimeout(() => scrollToBottom(), 300);
            return;
          }

          const item = welcomeQueueRef.current[index];
          setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
          setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
          scrollToBottom();
          if (item.audioUrl) {
            try {
              const fullUrl = getFullAudioUrl(item.audioUrl);
              logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Welcome');
              if (audioRef.current) audioRef.current.pause();
              const audio = new Audio(fullUrl);
              audioRef.current = audio;
              setIsAISpeaking(true);
              audio.onended = () => { setIsAISpeaking(false); playIndex(index + 1); };
              audio.onerror = () => { setIsAISpeaking(false); playIndex(index + 1); };
              await audio.play();
            } catch {
              setIsAISpeaking(false);
              playIndex(index + 1);
            }
          } else {
            setIsAISpeaking(false);
            playIndex(index + 1);
          }
        };

        playIndex(0);
      } catch (e: any) {
        const errorMessage = e?.response?.data?.message || e?.message || '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤—å—é';
        showError(errorMessage);
      }
    };

    loadAndPlayWelcome();
    return () => { isCancelled = true; };
  }, [interviewId, scrollToBottom, showError]);

  // –ü—Ä–æ—Å—Ç–æ–π –∞–≤—Ç–æ—Å–∫—Ä–æ–ª–ª –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
  useEffect(() => {
    scrollToBottom();
  }, [messages, scrollToBottom]);



  // Timer logic ‚Äî moved below to avoid using handlers before declaration

  const addQuestionCard = useCallback((questionIndex: number, textOverride?: string) => {
    console.log(`‚ûï Adding question card ${questionIndex + 1}`);
    const base = createQuestionCard(questionIndex, [], answerTimeSec);
    const newQuestionCard = { ...base, text: textOverride ?? base.text } as QuestionCard;
    setQuestionCards(prev => {
      const id = `question-card-${Math.max(0, questionIndex)}`;
      if (prev.some(card => card.id === id)) {
        console.log('üîÅ Skip adding duplicate question card', { id });
        return prev;
      }
      return [...prev, newQuestionCard];
    });
    
    // –î–æ–±–∞–≤–ª—è–µ–º question card –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
    const questionCardMsg = { 
      id: `question-card-${questionIndex}`, 
      content: `question-card-${questionIndex}`, 
      isVisible: true, 
      isNew: true,
      type: 'question-card',
      questionCard: newQuestionCard
    } as any;
    setMessages(prev => [...prev, questionCardMsg]);
    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
    
    setTimeout(() => {
      setQuestionCards(prev => prev.map(card =>
        card.id === newQuestionCard.id ? { ...card, isNew: false } : card
      ));
      setMessages(prev => prev.map(msg => 
        msg.id === `question-card-${questionIndex}` ? { ...msg, isNew: false } : msg
      ));
    }, 500);
  }, [answerTimeSec, scrollToBottom]);

  const completeQuestion = useCallback((questionIndex: number) => {
    console.log(`‚úÖ Completing question ${questionIndex + 1}`);
    setQuestionCards(prev => markQuestionAsCompleted(prev, questionIndex));
  }, []);

  // Event handlers
  const { isRecording: isRec, startRecording, stopRecording, audioBlob, clearAudio } = useAudioRecording();
  const [isPendingMicUpload, setIsPendingMicUpload] = useState(false);

  const handleMicrophoneTest = useCallback(() => {
    console.log('üé§ Starting microphone test');
    setStage('recording-test');
    setIsRecording(true);
    void startRecording();
    setIsAISpeaking(false);
    

    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
  }, []);

  const handleContinueToInstructions = useCallback(() => {
    console.log('üìã Opening instructions modal');
    setShowContinueButton(false);
    setIsInstructionsModalOpen(true);
  }, []);

  const handleStopMicrophoneTest = useCallback(async () => {
    if (isStopInProgressRef.current) { return; }
    isStopInProgressRef.current = true;
    console.log('‚èπÔ∏è Stopping microphone test');
    setIsRecording(false);
    try {
      stopRecording();
    } catch {}
    setIsTranscribing(true);
    // –í–∫–ª—é—á–∞–µ–º —Ä–µ–∞–∫—Ç–∏–≤–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–æ—è–≤–ª–µ–Ω–∏—è blob –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏
    setIsPendingMicUpload(true);
  }, [audioBlob, clearAudio, interviewId, scrollToBottom, stopRecording, showError]);

  // –†–µ–∞–∫—Ç–∏–≤–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –∑–∞–ø–∏—Å–∏, –∫–æ–≥–¥–∞ blob –≥–æ—Ç–æ–≤
  useEffect(() => {
    const upload = async () => {
      if (!isPendingMicUpload || !audioBlob) return;
      try {
        let resp: any = { data: {} };
        const fileType = audioBlob.type || 'audio/webm';
        const fileExt = fileType.includes('wav') ? 'wav' : (fileType.includes('ogg') ? 'ogg' : 'webm');

        const file = new File([audioBlob], `mic-test.${fileExt}`, { type: fileType });
        resp = await apiClient.candidates.testMicrophone(interviewId, file);
        setIsTranscribing(false);

        // –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        const userMsg = { id: 'user-response', content: '–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞', isVisible: true, isNew: true, isUser: true } as any;
        setMessages(prev => [...prev, userMsg]);
        setTimeout(() => scrollToBottom(), 10);

        const isOk = (resp.data as any)?.isReadyForInterview === true;
        const responses = isOk ? positiveResponsesRef.current : negativeResponsesRef.current;

        // –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ responses –ø–æ –æ—á–µ—Ä–µ–¥–∏
        const playResponses = async (idx: number) => {
          if (idx >= responses.length) {
            // –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø—Ä–æ–∏–≥—Ä–∞–Ω—ã
            if (!isOk) {
              setStage('welcome');
              setShowMicrophoneCard(true);
            } else {
              setShowContinueButton(true);
            }
            return;
          }

          const item = responses[idx];
          if (item?.text) {
            const id = `test-feedback-${idx}-${Date.now()}`;
            setMessages(prev => [...prev, { id, content: item.text!, isVisible: true, isNew: true } as any]);
            setTimeout(() => setMessages(prev => prev.map(m => (m.id === id ? { ...m, isNew: false } : m))), 500);
            scrollToBottom();
          }

          if (item?.audioUrl) {
            try {
              const fullUrl = getFullAudioUrl(item.audioUrl);
              logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:TestFeedback');
              if (audioRef.current) audioRef.current.pause();
              const audio = new Audio(fullUrl);
              audioRef.current = audio;
              setIsAISpeaking(true);
              audio.onended = () => { 
                setIsAISpeaking(false); 
                playResponses(idx + 1);
              };
              audio.onerror = () => { 
                setIsAISpeaking(false); 
                playResponses(idx + 1);
              };
              await audio.play();
            } catch {
              setIsAISpeaking(false);
              playResponses(idx + 1);
            }
          } else {
            // –ù–µ—Ç –∞—É–¥–∏–æ - –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é —á–µ—Ä–µ–∑ –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É
            setTimeout(() => {
              playResponses(idx + 1);
            }, 800);
          }
        };

        // –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        playResponses(0);
      } catch (e: any) {
        setIsTranscribing(false);
        const errorMessage = e?.response?.data?.message || e?.message || '–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞';
        showError(errorMessage);
      } finally {
        setIsPendingMicUpload(false);
        clearAudio();
        isStopInProgressRef.current = false;
      }
    };
    void upload();
  }, [isPendingMicUpload, audioBlob, interviewId, clearAudio, scrollToBottom, showError]);

  const handleStartInterview = useCallback(async () => {
    console.log('üöÄ Starting interview');
    setIsInstructionsModalOpen(false);
    setStage('question');
    setTimeRemaining(answerTimeSec);
    setCurrentQuestionIndex(0);
    setIsAISpeaking(true);
    setTimerStarted(false); // –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –ø–æ—Å–ª–µ –æ–∑–≤—É—á–∫–∏ –≤–æ–ø—Ä–æ—Å–∞

    try {
      await apiClient.candidates.startInterview(interviewId);
    } catch (e: any) {
      // –ü—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –∏ –±–ª–æ–∫–∏—Ä—É–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
      const errorMessage = e?.response?.data?.message || e?.message || '–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é';
      showError(errorMessage);
      return;
    }

    const fetchAndPlay = async () => {
      try {
        const { data } = await apiClient.candidates.getCurrentQuestion(interviewId);
        if (!data || !data.questionId) {
          try { await apiClient.candidates.endInterview(interviewId); } catch {}
          const playCompletion = async (idx: number) => {
            if (idx >= completionQueueRef.current.length) {
              // –ü–æ—Å–ª–µ completion –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ candidate-questions –±–µ–∑ –∞–≤—Ç–æ–∑–∞–ª–∏–≤–∫–∏ –≤ —á–∞—Ç
              setStage('candidate-questions');
              return;
            }
            const item = completionQueueRef.current[idx];
            setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
            setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
            scrollToBottom();
            if (item.audioUrl) {
              try {
                const fullUrl = getFullAudioUrl(item.audioUrl);
                logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Completion');
                if (audioRef.current) audioRef.current.pause();
                const audio = new Audio(fullUrl);
                audioRef.current = audio;
                setIsAISpeaking(true);
                audio.onended = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
                audio.onerror = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
                await audio.play();
              } catch {
                setIsAISpeaking(false);
                playCompletion(idx + 1);
              }
            } else {
              setIsAISpeaking(false);
              playCompletion(idx + 1);
            }
          };
          playCompletion(0);
          return;
        }

        // –í–ê–ñ–ù–û: —Å–Ω–∞—á–∞–ª–∞ —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–µ–∫—É—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
        setCurrentQuestionId(data.questionId || null);
        currentQuestionIdRef.current = (data.questionId as any) ?? null;
        console.log('üÜî Set currentQuestionId from getCurrentQuestion:', currentQuestionIdRef.current);

        const qNum = ((data as any).index ?? 1) - 1;
        setCurrentQuestionNumber((data as any).index || 1);
        setTotalQuestions((data as any).total || null);
        setCurrentQuestionIndex(Math.max(0, qNum));
        addQuestionCard(Math.max(0, qNum), data.text || '');
        const cardId = `question-card-${Math.max(0, qNum)}`;
        setTimeout(() => setQuestionCards(prev => prev.map(card => card.id === cardId ? { ...card, isNew: false } : card)), 500);
        scrollToBottom();

        if (data.audioUrl) {
          try {
            const fullUrl = getFullAudioUrl(data.audioUrl);
            logAudioUrl(data.audioUrl, fullUrl, 'InterviewProcess:Question');
            if (audioRef.current) audioRef.current.pause();
            const audio = new Audio(fullUrl);
            audioRef.current = audio;
            setIsAISpeaking(true);
            audio.onended = () => { setIsAISpeaking(false); setTimerStarted(true); };
            audio.onerror = () => { setIsAISpeaking(false); setTimerStarted(true); };
            await audio.play();
          } catch { setIsAISpeaking(false); setTimerStarted(true); }
        } else {
          setIsAISpeaking(false);
          setTimerStarted(true);
        }
      } catch (e: any) {
        const errorMessage = e?.response?.data?.message || e?.message || '–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞';
        showError(errorMessage);
      }
    };

    fetchAndPlay();
  }, [addQuestionCard, interviewId, scrollToBottom, showError]);

  const handleRecordAnswer = useCallback(() => {
    console.log('üéôÔ∏è Starting to record answer for question', currentQuestionIndex + 1);
    setStage('recording-answer');
    setIsRecording(true);
    setIsAISpeaking(false);
    void startRecording();
    // –ù–ï —Ç—Ä–æ–≥–∞–µ–º —Ç–∞–π–º–µ—Ä - –æ–Ω –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –µ—Å—Ç—å
  }, [currentQuestionIndex, startRecording]);

  const handleSkipQuestion = useCallback(async () => {
    console.log(`‚è≠Ô∏è Skipping question ${currentQuestionIndex + 1}`, {
      interviewId,
      currentQuestionId: currentQuestionIdRef.current,
      reason: 'user_action_or_timeout'
    });
    completeQuestion(currentQuestionIndex);
    setTimerStarted(false);
    setTimeRemaining(answerTimeSec);
    try {
      if (currentQuestionIdRef.current != null) {
        console.log('üì§ submitAnswer(skip=true) ‚Üí sending', {
          interviewId,
          questionId: currentQuestionIdRef.current,
          skip: true
        });
        await apiClient.candidates.submitAnswer(interviewId, currentQuestionIdRef.current, true);
        console.log('‚úÖ submitAnswer(skip=true) ‚Üí success');
      } else {
        console.warn('‚ö†Ô∏è Cannot submit skip: currentQuestionId is null');
      }
    } catch (e: any) {
      const errorMessage = e?.response?.data?.message || e?.message || '–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞';
      console.error('‚ùå submitAnswer(skip=true) failed:', errorMessage, e);
      showError(errorMessage);
      return;
    }

    try {
      console.log('üîÑ Fetching next question after skip', { interviewId });
      const { data } = await apiClient.candidates.getCurrentQuestion(interviewId);
      console.log('üì• getCurrentQuestion ‚Üí', data);
      if (!data || !data.questionId) {
        console.log('üèÅ No more questions, ending interview', { interviewId });
        try { await apiClient.candidates.endInterview(interviewId); } catch {}
        const playCompletion = async (idx: number) => {
          if (idx >= completionQueueRef.current.length) {
            // –ü–µ—Ä–µ—Ö–æ–¥ –∫ candidate-questions –±–µ–∑ –∞–≤—Ç–æ–∑–∞–ª–∏–≤–∫–∏
            setStage('candidate-questions');
            return;
          }
          const item = completionQueueRef.current[idx];
          setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
          setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
          scrollToBottom();
          if (item.audioUrl) {
            try {
              const fullUrl = getFullAudioUrl(item.audioUrl);
              logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Completion');
              if (audioRef.current) audioRef.current.pause();
              const audio = new Audio(fullUrl);
              audioRef.current = audio;
              setIsAISpeaking(true);
              audio.onended = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
              audio.onerror = () => { setIsAISpeaking(false); playCompletion(idx + 1); };
              await audio.play();
            } catch {
              setIsAISpeaking(false);
              playCompletion(idx + 1);
            }
          } else {
            setIsAISpeaking(false);
            playCompletion(idx + 1);
          }
        };
        playCompletion(0);
        return;
      }

      setCurrentQuestionId(data.questionId || null);
      currentQuestionIdRef.current = (data.questionId as any) ?? null;
      console.log('üÜî Set currentQuestionId from getCurrentQuestion (after skip):', currentQuestionIdRef.current);
      const qNumber = (((data as any).index ?? (currentQuestionIndex + 2)) as number) - 1;
      setCurrentQuestionNumber((data as any).index || (qNumber + 1));
      setTotalQuestions((data as any).total || totalQuestions);
      setCurrentQuestionIndex(Math.max(0, qNumber));
      addQuestionCard(Math.max(0, qNumber), data.text || '');
      const cardId = `question-card-${Math.max(0, qNumber)}`;
      setTimeout(() => setQuestionCards(prev => prev.map(card => card.id === cardId ? { ...card, isNew: false } : card)), 500);
      scrollToBottom();

      // –í–∞–∂–Ω–æ: –ø–µ—Ä–µ—Ö–æ–¥–∏–º –≤ —Å—Ç–∞–¥–∏—é –≤–æ–ø—Ä–æ—Å–∞, —á—Ç–æ–±—ã –∫–Ω–æ–ø–∫–∏ –æ—Ç—Ä–∏—Å–æ–≤–∞–ª–∏—Å—å
      setStage('question');

      setIsAISpeaking(false);
      setTimerStarted(false);
      setTimeRemaining(answerTimeSec);
      if (data.audioUrl) {
        try {
          const fullUrl = getFullAudioUrl(data.audioUrl);
          logAudioUrl(data.audioUrl, fullUrl, 'InterviewProcess:Question');
          if (audioRef.current) audioRef.current.pause();
          const audio = new Audio(fullUrl);
          audioRef.current = audio;
          setIsAISpeaking(true);
          audio.onended = () => { setIsAISpeaking(false); setTimerStarted(true); };
          audio.onerror = () => { setIsAISpeaking(false); setTimerStarted(true); };
          await audio.play();
        } catch { setIsAISpeaking(false); setTimerStarted(true); }
      } else { setTimerStarted(true); }
    } catch (e: any) {
      const errorMessage = e?.response?.data?.message || e?.message || '–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞';
      console.error('‚ùå getCurrentQuestion after skip failed:', errorMessage, e);
      showError(errorMessage);
    }
  }, [currentQuestionIndex, completeQuestion, addQuestionCard, interviewId, totalQuestions, scrollToBottom, showError]);

  // –î–∞–µ–º —Ç–∞–π–º–µ—Ä—É –¥–æ—Å—Ç—É–ø –∫ –ª–æ–≥–∏–∫–µ –ø—Ä–æ–ø—É—Å–∫–∞
  useEffect(() => {
    skipQuestionFnRef.current = () => { void handleSkipQuestion(); };
  }, [handleSkipQuestion]);

  const handleStopRecording = useCallback(() => {
    if (isStopInProgressRef.current || isSavingAnswer || isTranscribing) {
      console.log('‚èπÔ∏è Stop ignored: in-progress');
      return;
    }
    isStopInProgressRef.current = true;
    console.log('‚èπÔ∏è Stopping recording for question', currentQuestionIndex + 1, {
      interviewId,
      currentQuestionId: currentQuestionIdRef.current,
      stage
    });
    setIsRecording(false);
    setIsTranscribing(true);
    setIsSavingAnswer(true);

    stopRecording()
      .then((blob) => {
        if (!currentQuestionIdRef.current) {
          throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–æ–ø—Ä–æ—Å –¥–ª—è –æ—Ç–≤–µ—Ç–∞');
        }
        if (!blob || blob.size === 0) {
          throw new Error('–ê—É–¥–∏–æ–∑–∞–ø–∏—Å—å –ø—É—Å—Ç–∞—è');
        }
        const fileType = blob.type || 'audio/webm';
        const fileExt = fileType.includes('wav') ? 'wav' : (fileType.includes('ogg') ? 'ogg' : 'webm');
        const file = new File([blob], `answer.${fileExt}`, { type: fileType });
        console.log('üì§ submitAnswer(skip=false) ‚Üí sending', {
          interviewId,
          questionId: currentQuestionIdRef.current,
          skip: false,
          fileType: file.type,
          fileSize: file.size
        });
        return apiClient.candidates.submitAnswer(interviewId, currentQuestionIdRef.current, false, file);
      })
      .then((resp: any) => {
        console.log('‚úÖ submitAnswer(skip=false) ‚Üí success', resp?.data);
        setIsSavingAnswer(false);
        setIsTranscribing(false);
        completeQuestion(currentQuestionIndex);
        // –ï—Å–ª–∏ API —è–≤–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –Ω–µ—Ç ‚Äî –∑–∞–ø—É—Å–∫–∞–µ–º completion –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        if (resp && resp.data && resp.data.nextQuestion === false) {
          console.log('üèÅ nextQuestion=false in submitAnswer response ‚Äî finishing interview');
          // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∞–π–º–µ—Ä–∞ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ, —á—Ç–æ–±—ã –Ω–µ —Ç–∏–∫–∞–ª –≤–æ –≤—Ä–µ–º—è completion
          setTimerStarted(false);
          const playCompletion = (idx: number): Promise<void> => {
            if (idx >= completionQueueRef.current.length) {
              // –ü–µ—Ä–µ—Ö–æ–¥ –∫ candidate-questions –±–µ–∑ –∞–≤—Ç–æ–∑–∞–ª–∏–≤–∫–∏
              setStage('candidate-questions');
              return Promise.resolve();
            }
            const item = completionQueueRef.current[idx];
            setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
            setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
            scrollToBottom();
            if (item.audioUrl) {
              try {
                const fullUrl = getFullAudioUrl(item.audioUrl);
                logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Completion');
                if (audioRef.current) audioRef.current.pause();
                const audio = new Audio(fullUrl);
                audioRef.current = audio;
                setIsAISpeaking(true);
                return new Promise<void>((resolve) => {
                  audio.onended = () => { setIsAISpeaking(false); void playCompletion(idx + 1).then(resolve); };
                  audio.onerror = () => { setIsAISpeaking(false); void playCompletion(idx + 1).then(resolve); };
                  audio.play().catch(() => { setIsAISpeaking(false); void playCompletion(idx + 1).then(resolve); });
                });
              } catch {
                setIsAISpeaking(false);
                return playCompletion(idx + 1);
              }
            } else {
              setIsAISpeaking(false);
              return playCompletion(idx + 1);
            }
          };
          return apiClient.candidates.endInterview(interviewId)
            .catch(() => undefined)
            .then(() => playCompletion(0))
            .then(() => null as any); // –Ø–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º null, —á—Ç–æ–±—ã —Å–ª–µ–¥—É—é—â–∏–π then –ø—Ä–æ–ø—É—Å—Ç–∏–ª –æ–±—Ä–∞–±–æ—Ç–∫—É
        }
        console.log('üîÑ Fetching next question after answer', { interviewId });
        return apiClient.candidates.getCurrentQuestion(interviewId);
      })
      .then((resp: any) => {
        // –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –≤–µ—Ç–∫–∞ —É–∂–µ –∑–∞–≤–µ—Ä—à–∏–ª–∞ –∏–Ω—Ç–µ—Ä–≤—å—é, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        if (!resp || !resp.data) {
          return undefined;
        }
        const { data } = resp;
        console.log('üì• getCurrentQuestion ‚Üí', data);
        if (!data || !data.questionId) {
          console.log('üèÅ No more questions, ending interview', { interviewId });
          // –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º completion-—Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –ø—Ä–æ–ø—É—Å–∫–æ–º
          const playCompletion = (idx: number): Promise<void> => {
            if (idx >= completionQueueRef.current.length) {
              // –ü–µ—Ä–µ—Ö–æ–¥ –∫ candidate-questions –±–µ–∑ –∞–≤—Ç–æ–∑–∞–ª–∏–≤–∫–∏
              setStage('candidate-questions');
              return Promise.resolve();
            }
            const item = completionQueueRef.current[idx];
            setMessages(prev => [...prev, { id: item.id, content: item.text, isVisible: true, isNew: true } as any]);
            setTimeout(() => setMessages(prev => prev.map(m => (m.id === item.id ? { ...m, isNew: false } : m))), 500);
            scrollToBottom();
            if (item.audioUrl) {
              try {
                const fullUrl = getFullAudioUrl(item.audioUrl);
                logAudioUrl(item.audioUrl, fullUrl, 'InterviewProcess:Completion');
                if (audioRef.current) audioRef.current.pause();
                const audio = new Audio(fullUrl);
                audioRef.current = audio;
                setIsAISpeaking(true);
                return new Promise<void>((resolve) => {
                  audio.onended = () => { setIsAISpeaking(false); void playCompletion(idx + 1).then(resolve); };
                  audio.onerror = () => { setIsAISpeaking(false); void playCompletion(idx + 1).then(resolve); };
                  audio.play().catch(() => { setIsAISpeaking(false); void playCompletion(idx + 1).then(resolve); });
                });
              } catch {
                setIsAISpeaking(false);
                return playCompletion(idx + 1);
              }
            } else {
              setIsAISpeaking(false);
              return playCompletion(idx + 1);
            }
          };
          return apiClient.candidates.endInterview(interviewId)
            .catch(() => undefined)
            .then(() => playCompletion(0));
        }
        setCurrentQuestionId(data.questionId || null);
        currentQuestionIdRef.current = (data.questionId as any) ?? null;
        console.log('üÜî Set currentQuestionId from getCurrentQuestion (after answer):', currentQuestionIdRef.current);
        const qNumber = (((data as any).index ?? (currentQuestionIndex + 2)) as number) - 1;
        setCurrentQuestionNumber((data as any).index || (qNumber + 1));
        setTotalQuestions((data as any).total || totalQuestions);
        setCurrentQuestionIndex(Math.max(0, qNumber));
        addQuestionCard(Math.max(0, qNumber), data.text || '');
        const cardId = `question-card-${Math.max(0, qNumber)}`;
        setTimeout(() => setQuestionCards(prev => prev.map(card => card.id === cardId ? { ...card, isNew: false } : card)), 500);
        scrollToBottom();
        setStage('question');
        setTimerStarted(false);
        setTimeRemaining(answerTimeSec);
        // –ï—Å–ª–∏ —É —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –µ—Å—Ç—å –∞—É–¥–∏–æ ‚Äî –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –µ–≥–æ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏, –∏–Ω–∞—á–µ —Å—Ä–∞–∑—É —Å—Ç–∞—Ä—Ç—É–µ–º —Ç–∞–π–º–µ—Ä
        if (data.audioUrl) {
          try {
            const fullUrl = getFullAudioUrl(data.audioUrl);
            logAudioUrl(data.audioUrl, fullUrl, 'InterviewProcess:Question');
            if (audioRef.current) audioRef.current.pause();
            const audio = new Audio(fullUrl);
            audioRef.current = audio;
            setIsAISpeaking(true);
            audio.onended = () => { setIsAISpeaking(false); setTimerStarted(true); };
            audio.onerror = () => { setIsAISpeaking(false); setTimerStarted(true); };
            audio.play().catch(() => { setIsAISpeaking(false); setTimerStarted(true); });
          } catch {
            setIsAISpeaking(false);
            setTimerStarted(true);
          }
        } else {
          setTimerStarted(true);
        }
        return undefined;
      })
      .catch((e: any) => {
        const errorMessage = e?.response?.data?.message || e?.message || '–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞';
        console.error('‚ùå submitAnswer(chain) failed:', errorMessage, e);
        showError(errorMessage);
      })
      .finally(() => {
        setIsSavingAnswer(false);
        setIsTranscribing(false);
        isStopInProgressRef.current = false;
      });
  }, [currentQuestionIndex, interviewId, stopRecording, showError, scrollToBottom, completeQuestion, totalQuestions, addQuestionCard]);

  const handleCandidateQuestionsComplete = useCallback(() => {
    console.log('üéâ Interview completed');
    setIsAISpeaking(false);
  }, []);

  // –î–æ–±–∞–≤–ª—è–µ–º AI —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç
  const handleAddAiMessage = useCallback((content: string) => {
    const msg = { 
      id: `ai-${Date.now()}`, 
      content, 
      isVisible: true, 
      isNew: true 
    } as AIMessage;
    setMessages(prev => [...prev, msg]);
    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
    
    setTimeout(() => {
      setMessages(prev => prev.map(m => (m.id === msg.id ? { ...m, isNew: false } : m)));
    }, 500);
  }, [scrollToBottom]);

  // –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç
  const handleAddUserMessage = useCallback((content: string) => {
    const msg = { 
      id: `user-${Date.now()}`, 
      content, 
      isVisible: true, 
      isNew: true, 
      isUser: true 
    } as any;
    setMessages(prev => [...prev, msg]);
    
    // –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    setTimeout(() => scrollToBottom(), 10);
    setTimeout(() => scrollToBottom(), 100);
    setTimeout(() => scrollToBottom(), 300);
    
    setTimeout(() => {
      setMessages(prev => prev.map(m => (m.id === msg.id ? { ...m, isNew: false } : m)));
    }, 500);
  }, [scrollToBottom]);

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ AI —Ä–µ—á–∏ –¥–ª—è candidate-questions —ç—Ç–∞–ø–∞
  useEffect(() => {
    if (stage === 'candidate-questions') {
      console.log('üí¨ Starting candidate questions phase');
      setIsAISpeaking(true);
      
      const speakingTimer = setTimeout(() => {
        setIsAISpeaking(false);
      }, 8000);
      
      return () => clearTimeout(speakingTimer);
    }
  }, [stage]);

  const handleAISpeakingChange = useCallback((isSpeaking: boolean) => {
    setIsAISpeaking(isSpeaking);
  }, []);

  const handleNewMessage = useCallback(() => {
    scrollToBottom();
  }, [scrollToBottom]);

  // Timer logic (placed after handlers to avoid use-before-declare)
  useEffect(() => {
    if ((stage === 'question' || stage === 'recording-answer') && timerStarted && timeRemaining > 0) {
      timerRef.current = setTimeout(() => {
        setTimeRemaining(prev => {
          const newTime = prev - 1;
          console.log(`‚è∞ Timer tick: ${newTime} seconds remaining`, { stage, timerStarted });
        setQuestionCards(prev => updateQuestionTime(prev, newTime));
          return newTime;
        });
      }, 1000);
    } else if (timeRemaining === 0 && (stage === 'question' || stage === 'recording-answer') && timerStarted) {
      // –í—Ä–µ–º—è –∏—Å—Ç–µ–∫–ª–æ ‚Äî –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –∏–¥—ë—Ç, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç; –∏–Ω–∞—á–µ –ø—Ä–æ–ø—É—Å–∫
      console.log('‚è∞ Time up for question', currentQuestionIndex + 1, {
        interviewId,
        currentQuestionId,
        stage,
      });
      // –û—Ç–∫–ª—é—á–∞–µ–º —Ç–∞–π–º–µ—Ä, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤
      setTimerStarted(false);
      if (stage === 'recording-answer') {
        console.log('‚èπÔ∏è Auto-stopping recording due to timeout');
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –∏ –∏–Ω–∏—Ü–∏–∏—Ä—É–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –æ—Ç–≤–µ—Ç–∞
        handleStopRecording();
      } else {
        if (skipQuestionFnRef.current) {
          console.log('‚è≠Ô∏è Calling skipQuestion() due to time up');
          skipQuestionFnRef.current();
        } else {
          console.warn('‚ö†Ô∏è skipQuestionFnRef is not set');
        }
      }
    }

    return () => {
      if (timerRef.current) {
        clearTimeout(timerRef.current);
      }
    };
  }, [timeRemaining, stage, timerStarted, currentQuestionIndex, handleStopRecording]);

  // Debug info for current state
  console.log('üéØ Current state:', {
    stage,
    currentQuestionIndex,
    isRecording,
    isTranscribing,
    isSavingAnswer,
    isAISpeaking,
    timerStarted,
    timeRemaining
  });

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∞–≤–∞—Ç–∞—Ä
  const shouldShowAvatar = () => {
    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–≤–∞—Ç–∞—Ä –∫–æ–≥–¥–∞ AI –≥–æ–≤–æ—Ä–∏—Ç
    if (isAISpeaking && !isTranscribing && !isSavingAnswer) {
      return true;
    }
    
    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–≤–∞—Ç–∞—Ä –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –º–æ–ª—á–∞–Ω–∏—è –Ω–∞ —ç—Ç–∞–ø–µ candidate-questions
    if (stage === 'candidate-questions' && !isTranscribing && !isSavingAnswer) {
      return true;
    }
    
    return false;
  };

  // –ï–¥–∏–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
  const renderMessages = () => {
    return (
      <div className="flex flex-col space-y-4">
        {messages.map((message) => (
          message.isVisible && (
            <div key={message.id}>
              {('type' in message && message.type === 'microphone-card') ? (
                <div className="flex justify-start">
                  <MicrophoneTestCard />
                </div>
              ) : ('type' in message && message.type === 'reading-card') ? (
                <div className="flex justify-start">
                  <ReadingTestCard />
                </div>
              ) : ('type' in message && message.type === 'question-card' && 'questionCard' in message) ? (
                <div key={(message.questionCard as any).id}>
                  <QuestionProgressIndicator questionIndex={(message.questionCard as any).questionIndex} />
                                     <QuestionCardComponent 
                     questionCard={{
                       ...(message.questionCard as any),
                       timeRemaining: (message.questionCard as any).questionIndex === currentQuestionIndex && (stage === 'question' || stage === 'recording-answer') ? timeRemaining : null,
                       status: (message.questionCard as any).questionIndex === currentQuestionIndex && (stage === 'question' || stage === 'recording-answer') ? 'active' : 'completed'
                     }} 
                   />
                </div>
              ) : (
                <div className={`flex ${('isUser' in message && message.isUser) ? 'justify-end' : 'justify-start'}`}>
                  {message.id === 'test-msg' ? (
                    <ReadingTestCard />
                  ) : (
                    <MessageBubble 
                      content={message.content} 
                      isNew={message.isNew} 
                      isUser={'isUser' in message ? message.isUser : false}
                    />
                  )}
                </div>
              )}
            </div>
          )
        ))}
        
        {/* –ü–æ–∫–∞–∑—ã–≤–∞–µ–º CandidateQuestions —Ç–æ–ª—å–∫–æ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º —ç—Ç–∞–ø–µ */}
        {stage === 'candidate-questions' && (
          <CandidateQuestions 
            onComplete={handleCandidateQuestionsComplete}
            onAISpeakingChange={handleAISpeakingChange}
            onNewMessage={handleNewMessage}
            onAddAiMessage={handleAddAiMessage}
            onAddUserMessage={handleAddUserMessage}
            questionsOverride={(additionalQuestionsRef.current || [])
              .map((item, idx) => ({
                id: `api-q-${idx}`,
                question: item?.question || '',
                answer: item?.answer || ''
              }))
              .filter(q => !!q.question)}
          />
        )}
      </div>
    );
  };

  // Render stage content
  const renderStageContent = () => {
    console.log(`üé¨ Rendering stage: ${stage}`);
    
    switch (stage) {
      case 'welcome':
      case 'recording-test':
      case 'question':
      case 'recording-answer':
      case 'question-completed':
      case 'candidate-questions':
        return renderMessages();

      default:
        return null;
    }
  };

  // –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–Ω–æ–ø–∫–∞ "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å" –ø–æ –æ–±—Ä–∞–∑—Ü—É –∏–∑ Figma
  const RecordingButton = () => (
    <button
      onClick={stage === 'recording-answer' ? handleStopRecording : handleStopMicrophoneTest}
      className="bg-[#df1c41] relative rounded-[60px] h-16 w-auto hover:bg-[#c7193a] transition-colors duration-200 pulse-recording"
    >
      <div className="flex flex-row items-center relative size-full">
        <div className="box-border content-stretch flex flex-row gap-3 items-center justify-start pl-2 pr-8 py-2 relative size-full">
          {/* –ë–µ–ª—ã–π –∫—Ä—É–≥ —Å –∫—Ä–∞—Å–Ω—ã–º –∫–≤–∞–¥—Ä–∞—Ç–æ–º */}
          <div className="bg-[#ffffff] box-border content-stretch flex flex-row gap-2.5 items-center justify-center overflow-clip p-[8px] relative rounded-[100px] shrink-0 size-12">
            <div className="bg-[#df1c41] rounded shrink-0 size-5" />
          </div>
          {/* –¢–µ–∫—Å—Ç */}
          <div className="flex flex-col font-medium justify-center leading-[0] not-italic relative shrink-0 text-[#ffffff] text-[18px] text-center text-nowrap tracking-[-0.27px]">
            <p className="block leading-[24px] whitespace-pre font-Inter">–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å</p>
          </div>
        </div>
      </div>
    </button>
  );

  return (
    <div className="min-h-screen w-full" style={{ backgroundColor: 'var(--interview-bg)' }}>
      <div className="w-full h-full flex flex-col">
        <div className="flex flex-col gap-4 p-6 w-full h-full">
          
          {/* Header */}
          <div className="flex items-center justify-between w-full h-16">
            <Logo size="medium" />
            <HelpButton onClick={() => setIsHelpModalOpen(true)} />
          </div>

          {/* Main Content Area - —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≤—ã—Å–æ—Ç–æ–π –∏ z-index */}
          <div 
            className="overflow-hidden relative z-40"
            style={{ 
              height: 'calc(100vh - 64px - 96px - 128px - 48px)', // 100vh - header(64px) - downbar(96px) - footer(128px) - padding(48px)
              maxHeight: 'calc(100vh - 64px - 96px - 128px - 48px)'
            }}
          >
            <div 
              ref={scrollContainerRef}
              className="h-full overflow-y-auto px-6 pb-4 custom-scroll-container"
            >
              <div className="max-w-4xl mx-auto">
                {renderStageContent()}
                <div ref={messagesEndRef} />
              </div>
            </div>
          </div>

          {/* Fixed Downbar - —Å –∞–Ω–∏–º–∞—Ü–∏–µ–π */}
          <div className="fixed bottom-32 left-0 right-0 pointer-events-none z-50">
            <div className="w-full max-w-2xl mx-auto px-6 pointer-events-auto">
              <AnimatePresence mode="wait">
                {/* AI Avatar */}
                {shouldShowAvatar() && (
                  <motion.div 
                    initial={{ opacity: 0, y: 20 }}
                    animate={{ opacity: 1, y: 0 }}
                    exit={{ opacity: 0, y: 20 }}
                    transition={{ duration: 0.4 }}
                    className="flex justify-center"
                    key="avatar"
                  >
                    <AIAvatarWithWaves 
                      size={stage === 'question-completed' ? 'small' : 'large'} 
                      isSpeaking={isAISpeaking}
                    />
                  </motion.div>
                )}
                
                {/* Loader */}
                {(isTranscribing || isSavingAnswer) && (
                  <motion.div 
                    initial={{ opacity: 0, y: 20 }}
                    animate={{ opacity: 1, y: 0 }}
                    exit={{ opacity: 0, y: 20 }}
                    transition={{ duration: 0.4 }}
                    className="flex justify-center"
                    key="loader"
                  >
                    <div className="text-white rounded-full h-16 w-16 flex items-center justify-center shadow-lg" style={{ backgroundColor: 'var(--interview-accent)' }}>
                      <Loader2 className="w-12 h-12 animate-spin" strokeWidth={2} />
                    </div>
                  </motion.div>
                )}
              </AnimatePresence>
            </div>
          </div>

          {/* Fixed Footer - —Å –∫–Ω–æ–ø–∫–∞–º–∏ */}
          <div className="fixed bottom-0 left-0 right-0 pointer-events-none z-50">
            {/* Gradient Background */}
            <div className="bottom-controls-gradient h-32" />
            
            {/* Controls Container */}
            <div className="absolute inset-0 flex items-end justify-center pointer-events-none">
              <div className="w-full max-w-2xl mx-auto px-6 pb-8 pointer-events-auto">
                {/* Action Buttons */}
                <div className="flex justify-center">
                  {/* Welcome Stage */}
                  {stage === 'welcome' && showMicrophoneCard && !isAISpeaking && !isTranscribing && !isSavingAnswer && (
                    <Button
                      onClick={handleMicrophoneTest}
                      className="bg-[var(--interview-accent)] hover:bg-[var(--interview-accent-hover)] text-white px-8 py-4 font-medium shadow-md transition-all duration-200 hover:shadow-lg text-lg"
                      style={{ borderRadius: '30px', height: '56px' }}
                    >
                      –¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                    </Button>
                  )}

                  {/* Recording Test Stage */}
                  {stage === 'recording-test' && showContinueButton && !isAISpeaking && !isTranscribing && !isSavingAnswer && (
                    <Button
                      onClick={handleContinueToInstructions}
                      className="bg-[var(--interview-accent)] hover:bg-[var(--interview-accent-hover)] text-white px-8 py-4 font-medium shadow-md transition-all duration-200 hover:shadow-lg text-lg"
                      style={{ borderRadius: '30px', height: '56px' }}
                    >
                      –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å
                    </Button>
                  )}

                  {/* Question Stage */}
                  {stage === 'question' && !isAISpeaking && !isRecording && !isTranscribing && !isSavingAnswer && (
                    <div className="flex flex-col sm:flex-row gap-4">
                      <Button
                        onClick={handleRecordAnswer}
                        className="bg-[var(--interview-accent)] hover:bg-[var(--interview-accent-hover)] text-white px-8 py-4 font-medium shadow-md transition-all duration-200 hover:shadow-lg text-lg"
                        style={{ borderRadius: '30px', height: '56px' }}
                      >
                        –ó–∞–ø–∏—Å–∞—Ç—å –æ—Ç–≤–µ—Ç
                      </Button>
                      <Button
                        onClick={handleSkipQuestion}
                        className="border-2 border-gray-300 text-gray-700 hover:border-gray-400 hover:bg-gray-50 px-8 py-4 font-medium shadow-md transition-all duration-200 bg-white text-lg"
                        style={{ borderRadius: '30px', height: '56px' }}
                      >
                        –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                      </Button>
                    </div>
                  )}

                  {/* Recording Buttons */}
                  {stage === 'recording-answer' && isRecording && (
                    <RecordingButton />
                  )}
                  {stage === 'recording-test' && isRecording && (
                    <RecordingButton />
                  )}
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <HelpModal 
        isOpen={isHelpModalOpen} 
        onClose={() => setIsHelpModalOpen(false)} 
      />

      <InstructionsModal
        isOpen={isInstructionsModalOpen}
        onClose={() => setIsInstructionsModalOpen(false)}
        onStartInterview={handleStartInterview}
        questionsCount={totalQuestions || 3}
        answerTimeSec={answerTimeSec}
      />

      {/* –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –æ—à–∏–±–∫–∏ */}
      {isErrorModalOpen && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
          <div className="bg-white rounded-lg p-6 max-w-md mx-4">
            <div className="flex items-center mb-4">
              <AlertCircle className="h-6 w-6 text-red-500 mr-3" />
              <h3 className="text-lg font-semibold text-gray-900">–û—à–∏–±–∫–∞</h3>
            </div>
            <p className="text-gray-700 mb-6">{error}</p>
            <div className="flex justify-end space-x-3">
              <Button
                onClick={hideError}
                variant="outline"
                className="px-4 py-2"
              >
                –ó–∞–∫—Ä—ã—Ç—å
              </Button>
              <Button
                onClick={retryLoading}
                className="px-4 py-2 bg-[#e16349] text-white hover:bg-[#d14a31]"
              >
                –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–æ–≤–∞
              </Button>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}
